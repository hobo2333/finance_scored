文章连接：https://blog.csdn.net/sz464759898/article/details/43957433
线性模型的推广--广义线性模型

我们知道在普通的线性模型中有如下的假设：
1)响应变量Y和误差项ϵ正态性： 响应变量Y和误差项ϵ服从正态分布，且ϵ是一个具有零均值，同方差的特性。
2)预测量xi和未知参数βi的非随机性：预测量xi具有非随机性、可测且不存在测量误差；未知参数βi认为是未知但不具随机性的常数。
3)研究对象：如普通线性模型的输出项是随机变量Y。在随机变量众多的特点或属性里，比如分布、各种矩、分位数等等，普通线性模型主要研究响应变量的均值E[Y]。
               E[Y]=E[θTx+ϵ]=θTx
4)联接方式：所以我们的假设函数h(x)=θTx就相当于是预测Y的期望。这里的h(x)可以理解为一个响应函数，用来实现从x到y的映射。

此时我们会想到如果Y不是高斯分布会怎么样呢，那响应函数要怎么变化呢？于是可以把线性模型的假设扩展成如下：
1)响应变量的分布推广至指数分散族(exponential dispersion family).(正态分布、泊松分布、二项分布、负二项分布、伽玛分布、逆高斯分布都可以转化为指数分布族）
2)不变
3)研究对象还是E[Y]
4)联接方式：广义线性模型里采用的联连函数(link function)理论上可以是任意的。

指数族分布即为广义线性模型的概率分布(即响应变量Y的分布)
指数家族分布可定义为：
                      p(y;η)=b(y)exp(ηTT(y)−a(η))
其中: 
1. η被称为自然参数(natural parameters) 
2. 通常T(y) = y 
通过不同的a(η) 和 b(y) , T(y)可将指数家族分布变成不同的概率分布

一般来说，GLM有三个假设: 
1.y|x;θ~exponentialfamily(η) ,假设y|x;θ满足一个以η为参数的指数分布。例如，给定了输入x和参数θ，那么可以构建y关于η的表达式。(建立自然参数η与y之间的联系)
2.给定x，我们的目标是要确定T(y)，即 。大多数情况下T(y)=y，那么我们实际上要确定的是 。即给定x，假设我们的目标函数是 。
（在逻辑回归中期望值是，因此目标函数h是φ；在线性回归中期望值是μ，而高斯分布中 ，因此线性回归中目标函数 ）（目标是求响应变量的期望）
3.假设自然参数η和x是线性相关，即假设： （建立自然参数与x之间的联系）


线性模型的推导(演变成高斯分布):
线性模型中目标变量y(response variable)是连续的，由机器学习线性回归概率解释中可以得到结论:y给定x服从高斯分布 N(µ,σ2),在这里μ可能由x决定
因为(y|X ; θ)~ExpFamily(η)~N(μ,σ2) 由高斯分布函数可得:

                                           p(y;μ)=(1/√2π)exp(−(y−μ)2/2)
                                           ⟹(1/√2π)exp(−y2/2+μy−μ2/2)
                                           ⟹(1/√2π)exp(−y2/2)exp(μy−μ2/2)
与指数分布族函数P(y;η)= b(y)exp(η^T T(y)−a(y))对比可得
                                             η=µ
                                             b(y)=(1/√2π)exp(−y2/2)
                                             a(y)=-µ2/2
                                             T(y)=y
由于对于服从(μ,σ2)(μ,σ2)的高斯分布，其均值为μ,因此有: 
                                           hΘ(X)=E[(y|X;μ)]=μ
由以上推理得 η=μ所以有: 
                                           hΘ(X)=E[(y|X;μ)]=μ=η
                                           η=ΘTX
                                           hθ(X)=θTX
                                           
                                           
逻辑回归模型的推导(演变成伯努利分布): 
目标概率函数和指数家族函数之间的参数关系: 
Logistic Regression二分类服从伯努利(Bernoulli)分布，表示为： 
(y|X;θ)~ExpFamily(η)~Bernoulli(Φ)， 
                                     Φ = p(y=1|x;θ) 
                                     p(y;Φ)=Φ^y(1-Φ)1-y   y∈0,1
                                     ⟹exp(log(Φ^y (1-Φ)1-y))=exp(logΦ^y+log(1-Φ)1-y)
                                     ⟹exp(ylogΦ+(1−y)log(1−Φ))=exp(ylogΦ+log(1−Φ)−ylog(1−Φ))
                                     ⟹exp(ylogΦ1−Φ+log(1−Φ))
由于服从(Φ)的伯努利分布函数均值为Φ，得: 
                                      hΘ(X)=E[(y|X;Θ)]=E[(y;Φ)]=Φ
由以上推理得 Φ = 1/(1 + exp(−η)), 所以有:
                                       hΘ(X)=E[(y|X;θ)]=1/(1+exp(−η))
                                       η=θTX
                                        hΘ(X)=1/(1+exp(−ΘTX))





